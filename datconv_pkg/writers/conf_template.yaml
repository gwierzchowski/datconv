Writer: 
    Module: datconv.writers.dcxml
    CArg: 
        # If True, XML is formated in readable way (one tag in one line),
        # otherwise full record is placed in one line (more compact, suitable for computers).
        # default: true
        pretty:   true
        
        # Determines emcoding used in output XML file.
        # Note that if encoding is set to ascii some characters may be converted to XML/HTML compatibe special codes
        # Most raliable way is to set unicode here (default option)
        # See documantation of codecs standard Python library for possible encodings.
        # Note: This option is ignored in Python3, where always unicode coding is used what produce UTF-8 XML file.
        # default: utf8 (in Python2), unicode (in Python3 and above)
        encoding: unicode
        
        # Tag name to store records countin output footer, if not set records count will not be printed
        # default: null
        cnt_tag: Footer
        
        # attribute of cnt_tag tag to store records count, if not set records count will be printed as tag text
        # default: null
        cnt_attr: tranCount
        
        # if True, generic header (as initialized by Reader) is added as first tag of output file
        # default: true
        add_header: true
        
        # if True, generic footer (as initialized by Reader) is added as last tag of output file
        add_footer: true

Writer: 
    Module: datconv.writers.dcxpaths
    CArg:
        # If true, Wirter generate xpaths relatative to record tag, and will not generate
        # separate fields for replicated data (repeated tags; arrays) and not generate fields for tag's attributes.
        # The same setting must be applied in writers.dccsv if it uses configuration file generated by this Writer.
        # default: false
        simple_xpath: false
        
        # If true, Writer join fields with the same name contained in different records.
        # Generated Field Name does not contain record name prefix, and in place of record name '*' is placed.
        # default: false
        ignore_rectyp: false
        
        # If true, Writer join fields with the same name contained in different paths of XML structure.
        # Generated XPath is in form './/FieldName' or '//FieldName' (depands on simple_xpath property).
        # default: false
        ignore_xpath: false
        
        # If true, Writer will not generate fields for XML attbibutes.
        # If simple_xpath is true, this option is automatically set to true.
        # default: false
        ignore_attr: false
        
        # if True, generic header (as initialized by Reader) is added as first line of output file
        # default: true
        add_header: true
        
        # If true, Writer will add data type information guessed from data.
        # default: false
        add_type: false
        
        # Separator in generated column name between record type and calumn name (has effect if ignore_rectyp = false).
        # default: "_"
        rectyp_separator: "."
        
Writer: 
    Module: datconv.writers.dccsv
    CArg:
        # This parameter specifies columns to be placed in outpot CSV file.
        # It may be one of 4 possible types or null:
        # - string: path to file that contain specification of columns in output file.
        #   This specification may be generated by (or based on file generated by) writers.dcxpaths. 
        #   See this module description for more details.
        #   Lines that begin with # sign in specification file are ignored.
        # - list: direct specification of columns in output file.
        #   It should be list of 4 element lists.
        #   Those 4 element lists are similar to lines in file specification described above.
        #   This option is suitable if we want very few columns
        # - integer: assuming that all records have the same fields, add columns based on first record
        # - dictionary or null: this runs writer in so called auto-mode.
        #   In this mode columns in output file are being added automatically as they are being fond in input file.
        #   Columns fould in previous records are also placed, so number of columns increase with consequtive records.
        #   This is possible to enforce certain number of columns from begin to ensure equal number of columns (see below).
        #   In this option column names are added (if configured - see below) at end of file.
        # default: null
        columns: out/CZEC8173.TMF.xpaths        # string: path to file that contain specification of columns in output file
        # or
        columns:                                # list: direct specification of columns in output file
            - ['ISN','*','ISN',null]
            - ['TIME','*','TIME',null]
        # or
        columns: 1                              # integer: assuming that all records have the same fields, adds columns based on first record
                                                # the number has currently no meaning (we advice to place 1 here).
        # or
        columns:                                # dictionary (auto) case
            ignore_rectyp: false                # like in writers.pdxpaths (see above)
            ignore_xpath:  false                # like in writers.pdxpaths (see above)
            ignore_attr:   false                # like in writers.pdxpaths (see above)
            colno:         160                  # enforce this number of columns from begin (they are filled with empty values (default: 0 - i.e. option not active)

        # Determines weather simple xpaths are used in column specification (see option description in writers.pdxpaths above).
        # This option actually determines if function lxml.etree.Element.find or .xpath is used (see lxml documentation).
        # find is less capable but about 25% faster than xpath - therefore this option.
        # default: false
        simple_xpath: false
       
        # If True, generic header (as initialized by Reader) is added as first line of output file.
        # default: false
        add_header: false

        # If True, line with column names (fields) is added before data or after data (in case of auto option).
        # default: true
        col_names: true

        # Python csv writer class constructor options. See documantation of csv standard Python library.
        # Caution: Escape characters must be contained in double quotes ('\n' will not work).
        # default: null
        csv_opt:
            lineterminator: "\n"
            
Writer:
    Module: datconv.writers.dcjson
    CArg:
        # If True, generic header (as initialized by Reader) is added as first object of output file.
        # default: true
        add_header: true
        
        # If True, generic footer (as initialized by Reader) is added as last object of output file.
        # default: true
        add_footer: true
        
        # If True, adds newline character after each record.
        # default: true
        add_newline: true
        
        # 0 - does not convert (all values are text) 
        # 1 - tries to convert velues to int, bool or float (do not quote in json file) - little slower
        # 2 - like 1 but in addition checks if int values fits in 64 bits, if not place them as string value
        # default: 2
        convert_values: 2
        
        # Text that is converted to JSON null value (apply if convert_values is True)
        # default: 'None'
        null_text: ''
        
        # If True, order of keys in json output match order in source
        # default: false
        preserve_order: false
        
        # Name of key to store XML text
        # default: 'text'
        text_key: '_text_'
        
        # If True, XML text key will be eliminated if there are no other tag components
        # default: true
        text_eliminate: true
        
        # If True, XML properties are being saved in JSON file
        # default: true
        with_prop: true
        
        # If True, XML root tag for records (aka record type) will not be saved in JSON file 
        # (simplifies output layout in case there is one record type)
        # default: false
        ignore_rectyp: true
        
        # Dictionary with json.dump() options. See documentation of json standard Python library.
        # default: null
        json_opt: 
            indent: 2
